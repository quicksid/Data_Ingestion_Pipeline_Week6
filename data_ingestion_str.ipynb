{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVpNEFBi5J9v",
        "outputId": "3818ffbb-9ef0-4f08-d460-a43ce6de602d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jATzpqGSAuQe"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftBr-jCPBLUH",
        "outputId": "02425e10-617e-4201-c8d0-9dcaf32a3e91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root 64 Jul 14 04:48 kaggle.json\n"
          ]
        }
      ],
      "source": [
        "!ls -lha kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdis6Hq1BQ1f"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lfL0FulpBUeQ"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_hDlnAXBg1p"
      },
      "outputs": [],
      "source": [
        "!chmod 600 /root/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmWMFW7fBlsl",
        "outputId": "8251e663-efe2-44f0-b9fe-2c242a937ab7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRgJy1nRBv7Y",
        "outputId": "862fc223-2c48-497a-fc78-7f260cdaf4d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ref                                                                 title                                                size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
            "------------------------------------------------------------------  --------------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
            "rabieelkharoua/students-performance-dataset                         üìö Students Performance Dataset üìö                     66KB  2024-06-12 23:09:20          13710        284  1.0              \n",
            "nelgiriyewithana/most-streamed-spotify-songs-2024                   Most Streamed Spotify Songs 2024                    496KB  2024-06-15 18:50:51          10365        213  1.0              \n",
            "ihelon/coffee-sales                                                 Coffee Sales                                         10KB  2024-07-03 20:04:43           2673         55  1.0              \n",
            "tarktunataalt/2023-global-country-development-and-prosperity-index  2023 Global Country Development & Prosperity Index    7KB  2024-06-29 22:46:03            896         22  1.0              \n",
            "oleksiimartusiuk/1500-tv-shows-ranked                               1500+ TV Shows by Ratings                           676KB  2024-07-08 03:44:01            646         23  1.0              \n",
            "kapturovalexander/online-shop-2023                                  üè™üè¨üõçÔ∏èüõí Online shop 2023                                3KB  2024-07-10 15:36:20            822         24  1.0              \n",
            "sahityasetu/motor-vehicle-collisions-crashes-usa                    Motor Vehicle Collisions - Crashes: USA              82MB  2024-07-10 18:45:35            430         21  0.9411765        \n",
            "ambaliyagati/spotify-dataset-for-playing-around-with-sql            Spotify dataset                                     302KB  2024-06-17 10:48:20           2056         45  1.0              \n",
            "mithilesh9/amazon-sales-data-analysis                               Amazon Sales Data                                     5KB  2024-06-24 08:39:17            770         22  0.9411765        \n",
            "gorororororo23/plant-growth-data-classification                     Plant Growth Data Classification                      4KB  2024-07-10 00:41:02            640         24  1.0              \n",
            "omarsobhy14/hotel-revenue2024                                       Hotel Revenue2024 üè®üí∞                                  2KB  2024-07-09 11:59:08            611         27  1.0              \n",
            "nikhil7280/weather-type-classification                              Weather Type Classification                         186KB  2024-06-23 18:15:05           3232         61  1.0              \n",
            "utsavdey1410/food-nutrition-dataset                                 Food Nutrition Dataset                              694KB  2024-06-29 19:42:01           1878         50  1.0              \n",
            "fahmidachowdhury/e-commerce-sales-analysis                          üìà E-Commerce Sales Analysis                          35KB  2024-07-04 20:02:23           1181         32  0.9411765        \n",
            "dataanalyst001/world-population-by-country-2024                     World Population by country 2024                      6KB  2024-07-04 09:47:58           1517         34  1.0              \n",
            "kapturovalexander/food-orders                                       üòãüçóüçñ Food orders                                     846KB  2024-07-09 11:52:31            683         27  1.0              \n",
            "ritiksharma07/data-science-job-listings-from-glassdoor              Data Science Jobs & Salaries 2024                   303KB  2024-06-17 09:26:45           1390         29  1.0              \n",
            "thamersekhri/euro-2024-matches                                      Euro 2024 Matches Stats                               8KB  2024-07-12 17:59:20            635         34  1.0              \n",
            "dataanalyst001/population-of-all-us-cities-2024                     Population of all US Cities 2024                      8KB  2024-07-04 12:00:17            770         23  1.0              \n",
            "melissamonfared/formula-1                                           Formula 1 Racing (1950 - 2024)                        6MB  2024-07-06 15:01:05            172         96  1.0              \n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaNaTfLuByef",
        "outputId": "facdce34-e5a0-4325-9433-5c2d78196e24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/mohamedbakhet/amazon-books-reviews\n",
            "License(s): CC0-1.0\n",
            "Downloading amazon-books-reviews.zip to /content\n",
            " 99% 1.06G/1.06G [00:17<00:00, 39.2MB/s]\n",
            "100% 1.06G/1.06G [00:17<00:00, 63.9MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d mohamedbakhet/amazon-books-reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFABGk4vCDbQ",
        "outputId": "284f1745-8ad2-496a-f468-44286c037ca1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  amazon-books-reviews.zip\n",
            "  inflating: Books_rating.csv        \n",
            "  inflating: books_data.csv          \n"
          ]
        }
      ],
      "source": [
        "!unzip amazon-books-reviews.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm amazon-books-reviews.zip"
      ],
      "metadata": {
        "id": "a0S0b90Ceq0v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrSrlAw6Cc4J"
      },
      "source": [
        "## **File Reading Approaches**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-9UzoxMCMhc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0e67AdbEcI5"
      },
      "source": [
        "#### **Pandas:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ItKMfVojCtxe"
      },
      "outputs": [],
      "source": [
        "df_ratings = pd.read_csv('Books_rating.csv')\n",
        "df_books = pd.read_csv('books_data.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1nLl2S5DO0-"
      },
      "source": [
        "> Pandas took almost ~1 minute to load the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PX-wXjcC8_u"
      },
      "outputs": [],
      "source": [
        "# Deleting the dataframes\n",
        "\n",
        "lst = [df_ratings, df_books]\n",
        "del lst\n",
        "del df_ratings, df_books"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yW27bRZLUCM4"
      },
      "source": [
        "### **Files:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1tYHJU8EadM",
        "outputId": "3bda420c-6bde-46be-9359-f82dd6fdcd13"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:distributed.worker.memory:Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 1.31 GiB -- Worker memory limit: 1.86 GiB\n",
            "WARNING:distributed.worker.memory:Worker is at 80% memory usage. Pausing worker.  Process memory: 1.51 GiB -- Worker memory limit: 1.86 GiB\n",
            "INFO:distributed.core:Event loop was unresponsive in Scheduler for 4.70s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.\n",
            "INFO:distributed.core:Event loop was unresponsive in Worker for 5.14s.  This is often caused by long-running GIL-holding functions or moving large chunks of data. This can cause timeouts and instability.\n",
            "WARNING:distributed.worker.memory:Unmanaged memory use is high. This may indicate a memory leak or the memory may not be released to the OS; see https://distributed.dask.org/en/latest/worker-memory.html#memory-not-released-back-to-the-os for more information. -- Unmanaged memory: 3.49 GiB -- Worker memory limit: 1.86 GiB\n"
          ]
        }
      ],
      "source": [
        "with open('Books_rating.csv', 'r') as f:\n",
        "  df_ratings = f.read()\n",
        "\n",
        "with open('books_data.csv', 'r') as f:\n",
        "  df_books = f.read()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1Ed1y_sVBEq"
      },
      "source": [
        "> Reading by open() & read() function takes ~ 15 seconds to read the files. Which is an improvement over the Pandas library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQ1DzxUiU3kh"
      },
      "outputs": [],
      "source": [
        "with open('Books_rating.csv', 'r') as f:\n",
        "  df_ratings = f.readlines()\n",
        "\n",
        "with open('books_data.csv', 'r') as f:\n",
        "  df_books = f.readlines()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OG9kgWcidE_6"
      },
      "source": [
        "> - Reading by open() & readlines() function takes ~ 5 seconds to read the files. Which is much faster compared to read() function and Pandas library.\n",
        "> - However, readlines() method returns a list where each item of the list is a complete sentence in a file. Since it appends each line to the list and then returns the entire list it will be time consuming if the file size is quite large."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ym6h-E8o9LwT"
      },
      "source": [
        "### **Dask File Reading:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1JomkS-x9UT-"
      },
      "outputs": [],
      "source": [
        "#from dask.distributed import Client\n",
        "\n",
        "#client = Client(n_workers=1, threads_per_worker=4, processes=False, memory_limit='2GB')\n",
        "#client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMZJDWODBzCj"
      },
      "outputs": [],
      "source": [
        "import dask.dataframe as dd\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "df_ratings = dd.read_csv('Books_rating.csv', dtype = {'Id':'object'})\n",
        "df_books = dd.read_csv('books_data.csv')\n",
        "\n",
        "#len(df_ratings), len(df_books)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SX01hlOHL7R"
      },
      "source": [
        "> Data got loaded faster but Memory leak happened and the length of dataframe is not same."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofEu_zjiJNtM"
      },
      "source": [
        "### **Modin API:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WtmwVrvRJcoH"
      },
      "outputs": [],
      "source": [
        "!pip install -U ipykernel\n",
        "!pip install modin[all]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zd0JuyyTHTer",
        "outputId": "05d0ccc2-7e95-4c58-c79c-9155db8c8573"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "UserWarning: The size of /dev/shm is too small (6133121024 bytes). The required size at least half of RAM (6804715520 bytes). Please, delete files in /dev/shm or increase size of /dev/shm with --shm-size in Docker. Also, you can can override the memory size for each Ray worker (in bytes) to the MODIN_MEMORY environment variable.\n",
            "2024-07-13 19:27:51,074\tINFO worker.py:1788 -- Started a local Ray instance.\n"
          ]
        }
      ],
      "source": [
        "import modin.pandas as mpd\n",
        "\n",
        "df_ratings = mpd.read_csv('Books_rating.csv')\n",
        "df_books = mpd.read_csv('books_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df_ratings), len(df_books)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rx-XRCP9lKK_",
        "outputId": "f24e7763-ad94-4da9-fbf9-bfe1cec02aaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3000000, 212404)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Data loaded slowly in case of Modin and also Memory leak happened and the length of dataframe is not same as original."
      ],
      "metadata": {
        "id": "MVq6jb8XlOtA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLSzEvoVYL0Q"
      },
      "source": [
        "### **Creating Utility File for data ingestion:**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm utility.py\n",
        "!rm file.yaml"
      ],
      "metadata": {
        "id": "lUxgZex_e_oi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwtqdRoDIF7s",
        "outputId": "a3e1fc97-aac8-4007-cfbb-222bbcabf3f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting file.yaml\n"
          ]
        }
      ],
      "source": [
        "%%writefile file.yaml\n",
        "file_type: csv\n",
        "dataset_name: df_rating\n",
        "file_name: Books_rating\n",
        "table_name: books_rating\n",
        "inbound_delimiter: \",\"\n",
        "outbound_delimiter: \"|\"\n",
        "skip_leading_rows: 1\n",
        "columns:\n",
        "    - id\n",
        "    - title\n",
        "    - price\n",
        "    - user_id\n",
        "    - profile_name\n",
        "    - review_helpfulness\n",
        "    - review_score\n",
        "    - review_time\n",
        "    - review_summary\n",
        "    - review_text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile utility.py\n",
        "import logging\n",
        "import os\n",
        "import subprocess\n",
        "import yaml\n",
        "import datetime\n",
        "import gc\n",
        "import re\n",
        "\n",
        "\n",
        "def read_config_file(filepath):\n",
        "  with open(filepath, 'r') as stream:\n",
        "    try:\n",
        "      return yaml.safe_load(stream)\n",
        "    except yaml.YAMLError as exc:\n",
        "      logging.error(exc)\n",
        "\n",
        "def replacer(string, char):\n",
        "  pattern = re.escape(char) + '{2,}'\n",
        "  string = re.sub(pattern, char, string)\n",
        "  return string\n",
        "\n",
        "def col_header_val(df, config):\n",
        "  df_columns = df.columns\n",
        "  yaml_columns = config\n",
        "\n",
        "  #print(\"Original Columns: \", df_columns)\n",
        "  df_columns = df_columns.str.lower()\n",
        "  #print(\"Lower cased Columns: \", df_columns)\n",
        "  df_columns = df_columns.str.strip('_')\n",
        "  #print(\"Stripped by _ Columns: \", df_columns)\n",
        "  df_columns = list(df_columns)\n",
        "\n",
        "  for i in range(len(df_columns)):\n",
        "    df_columns[i] = replacer(df_columns[i], '_')\n",
        "  #print(\"Replaced repeating characters: \", df_columns)\n",
        "    df_columns[i] = re.sub('[$%^&*@!]', '', df_columns[i])\n",
        "    df_columns[i] = df_columns[i].strip('_')\n",
        "  #print(len(df_columns))\n",
        "\n",
        "  expected_col = yaml_columns\n",
        "  expected_col = list(expected_col)\n",
        "\n",
        "  if len(df_columns) == len(expected_col) and expected_col == df_columns:\n",
        "    print(\"column name and column length validation passed\")\n",
        "    return 1\n",
        "  else:\n",
        "    print(\"column name and column length validation failed\")\n",
        "    mismatched_columns_file = set(df_columns).difference(expected_col)\n",
        "    print(\"Columns not in YAML files\", mismatched_columns_file)\n",
        "    mismatched_YAML_file = set(expected_col).difference(df_columns)\n",
        "    print(\"Columns not in uploaded file\", mismatched_YAML_file)\n",
        "    logging.info(f'df columns: {df_columns}')\n",
        "    logging.info(f'expected columns: {expected_col}')\n",
        "    return 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XrKAf8bSShv",
        "outputId": "2b97a735-e5ec-4001-a756-46b30b984af4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting utility.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5ZoW649NPHR"
      },
      "source": [
        "### **Parameterizing process using YAML file:**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import utility as util"
      ],
      "metadata": {
        "id": "gYZB6-_Hg4S6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config_data = util.read_config_file('file.yaml')\n",
        "\n",
        "df_rating = pd.read_csv('Books_rating.csv', delimiter = config_data['inbound_delimiter'])\n",
        "#df_rating.head()\n",
        "\n",
        "df_rating.columns = ['id', '_title', 'price', 'user__id', 'profile__name', 'review_helpfulness', 'review_score', 'review__time', 'review_summary', 'review_text_']\n",
        "\n",
        "util.col_header_val(df_rating, config_data['columns'])"
      ],
      "metadata": {
        "id": "UktXNp47jNdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gzip\n",
        "\n",
        "with gzip.open('books_rating_zip.gz', 'wb') as f:\n",
        "  df_rating.to_csv(f, sep = '|')"
      ],
      "metadata": {
        "id": "Mtiv8RdCoOjD"
      },
      "execution_count": 58,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}